{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Google Speech Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import wave\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, AvgPool1D, MaxPool1D, ZeroPadding1D, BatchNormalization, Flatten, Dense, Activation\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw spoken digits data from Google Speech Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Xing stream size off by more than 1%, fuzzy seeking may be even more fuzzy than by design!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN\n",
      "\n",
      "DATA\n",
      "[[[ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  ...\n",
      "  [ 3.2614678e-02]\n",
      "  [-4.1543241e-03]\n",
      "  [ 4.8602957e-02]]\n",
      "\n",
      " [[ 2.0583554e-03]\n",
      "  [-7.7218879e-03]\n",
      "  [ 2.1314288e-03]\n",
      "  ...\n",
      "  [ 7.5069265e-03]\n",
      "  [ 9.1339042e-03]\n",
      "  [ 7.2912467e-03]]\n",
      "\n",
      " [[ 0.0000000e+00]\n",
      "  [ 7.1350287e-11]\n",
      "  [ 2.1943704e-11]\n",
      "  ...\n",
      "  [-1.6543496e-02]\n",
      "  [-1.6452722e-02]\n",
      "  [-1.5552191e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [-3.0598895e-11]\n",
      "  ...\n",
      "  [ 6.8211480e-04]\n",
      "  [ 2.3256075e-03]\n",
      "  [ 2.9792378e-03]]\n",
      "\n",
      " [[-3.2963223e-06]\n",
      "  [-5.5894852e-06]\n",
      "  [-3.7297962e-06]\n",
      "  ...\n",
      "  [ 1.2903062e-04]\n",
      "  [-1.5235022e-03]\n",
      "  [-4.9856215e-05]]\n",
      "\n",
      " [[ 1.5592575e-03]\n",
      "  [ 1.3773441e-03]\n",
      "  [ 8.2981586e-04]\n",
      "  ...\n",
      "  [ 5.4007769e-03]\n",
      "  [ 4.5046806e-03]\n",
      "  [ 3.1348467e-03]]]\n",
      "\n",
      "LABEL\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "\n",
      "TEST\n",
      "\n",
      "DATA\n",
      "[[[ 0.00000000e+00]\n",
      "  [ 0.00000000e+00]\n",
      "  [ 0.00000000e+00]\n",
      "  ...\n",
      "  [-2.94889629e-01]\n",
      "  [-2.05636825e-02]\n",
      "  [-3.44618887e-01]]\n",
      "\n",
      " [[ 0.00000000e+00]\n",
      "  [ 3.41689455e-11]\n",
      "  [-1.96498373e-11]\n",
      "  ...\n",
      "  [-2.12753527e-02]\n",
      "  [-2.18827426e-02]\n",
      "  [-8.25505424e-03]]\n",
      "\n",
      " [[-8.99958877e-07]\n",
      "  [-1.49267430e-06]\n",
      "  [-9.66429866e-07]\n",
      "  ...\n",
      "  [ 1.13268281e-04]\n",
      "  [ 4.59102084e-05]\n",
      "  [ 1.46113511e-04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.00000000e+00]\n",
      "  [ 0.00000000e+00]\n",
      "  [ 2.80278188e-12]\n",
      "  ...\n",
      "  [-3.97128891e-03]\n",
      "  [-2.90583260e-03]\n",
      "  [-2.48114020e-03]]\n",
      "\n",
      " [[ 0.00000000e+00]\n",
      "  [ 0.00000000e+00]\n",
      "  [-1.98081954e-10]\n",
      "  ...\n",
      "  [ 1.60724148e-02]\n",
      "  [ 1.67827178e-02]\n",
      "  [ 1.84039660e-02]]\n",
      "\n",
      " [[ 0.00000000e+00]\n",
      "  [ 1.14440984e-10]\n",
      "  [ 2.61059299e-11]\n",
      "  ...\n",
      "  [-2.62788404e-03]\n",
      "  [ 9.89975873e-03]\n",
      "  [ 1.26197869e-02]]]\n",
      "\n",
      "LABEL\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Xing stream size off by more than 1%, fuzzy seeking may be even more fuzzy than by design!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import soundfile as sf # install this in the kernel under Settings\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, AvgPool1D, MaxPool1D, ZeroPadding1D, BatchNormalization, Flatten, Dense, Activation\n",
    "import tensorflow as tf\n",
    "\n",
    "dataset_dir = 'datasets'\n",
    "CLASSES = [\"nightingale\", \"greenfinch\", \"quail\"]\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for class_name in CLASSES:\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    for mp3_file in glob.glob(os.path.join(class_dir, \"*.mp3\")):\n",
    "        data, sr = sf.read(mp3_file)\n",
    "        data = data.astype(np.float32) # Convert to 32-bit floating-point\n",
    "        data.resize((16000, 1)) # Resize to 1s (16kHz) with zero-padding, 1 channel\n",
    "        \n",
    "        x.append(data)\n",
    "        y.append(CLASSES.index(class_name))\n",
    "        \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)   \n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "x_test = np.array(x_test)\n",
    "y_test = to_categorical(np.array(y_test))\n",
    "\n",
    "print(\"\\nTRAIN\\n\")\n",
    "print(\"DATA\")\n",
    "print(x_train)\n",
    "print(\"\\nLABEL\")\n",
    "print(y_train)\n",
    "\n",
    "print(\"\\nTEST\\n\")\n",
    "print(\"DATA\")\n",
    "print(x_test)\n",
    "print(\"\\nLABEL\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for inference with fixed-point Q7.9 samples by scaling input data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_POINT = 9\n",
    "x_train /= 2**FIXED_POINT\n",
    "x_test  /= 2**FIXED_POINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export small dataset (250 random vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = np.random.permutation(len(y_test))[0:250]\n",
    "x_test_250 = x_test[perms]\n",
    "y_test_250 = y_test[perms]\n",
    "np.savetxt('x_test_gsc_250.csv', x_test_250.reshape((x_test_250.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test_gsc_250.csv', y_test_250, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build model M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_13 (Conv1D)          (None, 996, 32)           2592      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 996, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 249, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 247, 32)           3104      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 247, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 61, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 59, 64)            6208      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 59, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 14, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 12, 64)            12352     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 12, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPoolin  (None, 3, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 579       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,603\n",
      "Trainable params: 25,219\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(16000, 1)))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=80, strides=16, activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(MaxPool1D(pool_size=4))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "\n",
    "model.add(MaxPool1D(pool_size=4))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(MaxPool1D(pool_size=4))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "\n",
    "model.add(MaxPool1D(pool_size=4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=len(CLASSES)))\n",
    "model.add(Activation('softmax')) # SoftMax activation needs to be separate from Dense to remove it later on\n",
    "\n",
    "# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-3)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5993 - categorical_accuracy: 0.2500 - val_loss: 1.0360 - val_categorical_accuracy: 0.4167\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8186 - categorical_accuracy: 0.4583 - val_loss: 4.2053 - val_categorical_accuracy: 0.4167\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1431 - categorical_accuracy: 0.5000 - val_loss: 57.5174 - val_categorical_accuracy: 0.4167\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8680 - categorical_accuracy: 0.6042 - val_loss: 160.9853 - val_categorical_accuracy: 0.4167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27bc24ed70>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=4, batch_size=50, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 160.9853 - categorical_accuracy: 0.4167 - 22ms/epoch - 22ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "tf.Tensor(\n",
      "[[5 0 0]\n",
      " [5 0 0]\n",
      " [2 0 0]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate model on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 160.9853 - categorical_accuracy: 0.4167 - 21ms/epoch - 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "tf.Tensor(\n",
      "[[5 0 0]\n",
      " [5 0 0]\n",
      " [2 0 0]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test_250, y_test_250, verbose=2)\n",
    "pred_test_250 = model.predict(x_test_250)\n",
    "print(tf.math.confusion_matrix(y_test_250.argmax(axis=1), pred_test_250.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save('bird_recognition.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove SoftMax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install MicroAI for C inference code generation (kerascnn2c module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed\n",
      "  Downloading https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip (1.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from kerascnn2c==1.0.0) (3.0.3)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from kerascnn2c==1.0.0) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed\n",
    "import kerascnn2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate C code for the trained model with 16-bit fixed-point representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://5cdd2f3f-233b-4502-aefb-5f60342b07b0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://5cdd2f3f-233b-4502-aefb-5f60342b07b0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                           | Layer                            | Outputs                         \n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                 | input_5                          | conv1d_13                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "input_5                          | conv1d_13                        | batch_normalization_12          \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_13                        | batch_normalization_12           | max_pooling1d_12                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "batch_normalization_12           | max_pooling1d_12                 | conv1d_14                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_12                 | conv1d_14                        | batch_normalization_13          \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_14                        | batch_normalization_13           | max_pooling1d_13                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "batch_normalization_13           | max_pooling1d_13                 | conv1d_15                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_13                 | conv1d_15                        | batch_normalization_14          \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_15                        | batch_normalization_14           | max_pooling1d_14                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "batch_normalization_14           | max_pooling1d_14                 | conv1d_16                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_14                 | conv1d_16                        | batch_normalization_15          \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_16                        | batch_normalization_15           | max_pooling1d_15                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "batch_normalization_15           | max_pooling1d_15                 | flatten_3                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_15                 | flatten_3                        |                                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "After optimization:\n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                           | Layer                            | Outputs                         \n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                 | input_5                          | conv1d_13                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "input_5                          | conv1d_13                        | batch_normalization_12          \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_13                        | batch_normalization_12           | max_pooling1d_12                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "batch_normalization_12           | max_pooling1d_12                 | conv1d_14                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_12                 | conv1d_14                        | batch_normalization_13          \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_14                        | batch_normalization_13           | max_pooling1d_13                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "batch_normalization_13           | max_pooling1d_13                 | conv1d_15                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_13                 | conv1d_15                        | batch_normalization_14          \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_15                        | batch_normalization_14           | max_pooling1d_14                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "batch_normalization_14           | max_pooling1d_14                 | conv1d_16                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_14                 | conv1d_16                        | batch_normalization_15          \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_16                        | batch_normalization_15           | max_pooling1d_15                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "batch_normalization_15           | max_pooling1d_15                 | flatten_3                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_15                 | flatten_3                        |                                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "res = kerascnn2c.Converter(output_path=Path('gsc_output_fixed'),\n",
    "                           fixed_point=FIXED_POINT, # Number of bits for the fractional part, Q7.9 format\n",
    "                           number_type='int16_t', # Data type for weights/activations (16 bits quantization)\n",
    "                           long_number_type='int32_t', # Data type for intermediate results\n",
    "                           number_min=-(2**15), # Minimum value for 16-bit signed integers\n",
    "                           number_max=(2**15)-1 # Maximum value for 16-bit signed integers\n",
    "                          ).convert_model(copy.deepcopy(model))\n",
    "with open('gsc_model_fixed.h', 'w') as f:\n",
    "    f.write(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compile the 16-bit fixed-point C code for x86 and evaluate on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01m\u001b[Kgsc_output_fixed/model.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid cnn(const number_t (*)[16000], number_t*)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kgsc_output_fixed/model.c:184:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kleft operand of comma operator has no effect [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-value\u0007-Wunused-value\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  184 |     \u001b[01;35m\u001b[Kactivations2.max_pooling1d_15_output\u001b[m\u001b[K, // Last layer uses output passed as model parameter\n",
      "      |     \u001b[01;35m\u001b[K~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "Testing accuracy: 0.416667\n"
     ]
    }
   ],
   "source": [
    "!g++ -Wall -Wextra -pedantic -Ofast -o gsc_fixed -Igsc_output_fixed/ gsc_output_fixed/model.c main.cpp \n",
    "!./gsc_fixed x_test_gsc_250.csv y_test_gsc_250.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
